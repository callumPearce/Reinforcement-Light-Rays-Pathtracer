\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{epsfig,endnotes,listings, tabulary, graphicx, tabularx}
\usepackage{xcolor}
\usepackage{hyperref}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Reinforcement Light Rays Path-Tracer Progress Report}

\author{\IEEEauthorblockN{Callum Pearce}\\ cp15571@my.bristol.ac.uk }

\maketitle

\begin{abstract}
This document contains my weekly progress of my thesis as part of my 4th year masters unit COMSM0111 in 2018/19. It is mainly useful to myself for reflecting on the decisions I have made throughout the project and why I chose them.  However, I also hope it gives a detailed overview of how the project evolved with time for any other reader.
\end{abstract}


\section{Introduction}
Each section of this document describes a single week of work. For each section I have decided to include the following break down:

\begin{itemize}

\item  \textbf{Goals}: A few set goals I aimed to achieve in that week and the motivation behind them.

\item \textbf{Research/Implementation Details}: What was done, and how it was achieved.

\item \textbf{Resources}: Describes what resources were notably helpful during the week for research/implementation details.

\item \textbf{Reflection}: What I believed went well in the week, what to avoid in the future, and were the goal outlined achieved? Finally, if necessary, what has changed for the project as a whole?

\end{itemize}

\section*{Week 1}

Building off dome preliminary research I decided I had to build a ray-tracer in order to start any work with my project. This would be a good way of refreshing the basics of computer graphics.

\subsection{Goals}
\begin{enumerate}
\item Build a basic ray-tracer from scratch using only SDL and GLM as external libraries
\end{enumerate}

\subsection{Research/Implementation Goals}
This week was fairly simple in terms of implementation. I mainly based my work on the ray-tracer I built with my project partner in my 3rd year of university. I used a similar project structure and followed the lab-sheets from  \verb|COMS30015| by Carl Henrik Ek. By the end of the week I had built a ray-tracer which simulated the following in real-time:

\begin{itemize}
\item Constructing surfaces from triangle primitives and projecting them onto a 2D pixel plane for camera viewing via ray-tracing.
\item Supports camera movement
\item Direct illumination 
\end{itemize}

\subsection{Resources}
As mentioned the main resources used were those provided for \verb|COMS30015| by Carl Henrik Ek in 2017. They gave me a good refresher on all the core concepts of ray-tracing and the mathematics behind it. I have based my rendering on the Cornell Box scene which is a classical scene for testing computer graphical renderings. 

\subsection{Reflection}
I met my goal this week and built a well designed code-base to go with it.

\section*{Week 2}
With a basic ray-tracer up and running, it was then time to add global illumination (indirect lighting) into the rendered scene and other features to make the basic ray-tracer complete for my purposes.

\subsection{Goals}
\begin{enumerate}
\item Implement Monte-Carlo global illumination within the ray-tracing pipeline (to go alongside direct light. It is Monte-Carlo global illumination I am planning to base my reinforcement learning technique presented by NVIDIA \cite{dahm2017learning} on.

\item Create an object loader for the scene to test rendering in different scenes. I need a scene which has very low light levels in certain parts of the scene in order to show how reinforcement learning reduces noise in these areas.
\end{enumerate}

\subsection{Research/Implementation Goals}
My implementation worked as follows; for every pixel in the image, calculate the colour by finding the direct light at that point combined with the indirect light. Where indirect light was sampled by shooting a ray into the scene and scattering it, then recursively finding the illumination at these points (via Monte Carlo).

For the object loader, I read in all vertices and then built triangles to form the defined surfaces in the file by using fan-triangulation. These triangles would be built into the scene by a call to the script with the file name of the \verb|.obj| file to load.

I also introduced \verb|openmp| to the project to speed things up by parallelising the ray-tracers pixel painting loop. 

\subsection{Resources}
ScratchPixel 2.0 \cite{scratch-pixel} provided an excellent description of Monte Carlo global illumination for a ray-tracer. As for the object loader, opengl gave a great tutorial for simple processing of \verb|.obj| files \cite{opengl-obj}. 

\subsection{Reflection}
Monte Carlo global illumination was available for a custom scene as I had set out to achieve in this week. I also introduced an object loader which allows me to load in a scene of my choice, which will become especially useful when comparing different methods later on in the coursework. However, due to the introduction of global illumination the ray-tracer is far slower and takes a significant amount of time (nearly a day) to render a high quality image.

\section*{Week 3}
With global illumination in hand and a custom scene to test it on the project moved on to begin working on reimplementing the \textit{Learning Light transport the reinforced} way \cite{dahm2017learning} paper.

\subsection{Goals}
\begin{enumerate}
\item Take detailed notes of the \cite{dahm2017learning} paper and understand what needs to be changed with my current ray-tracer
\item Read through \cite{reinforcement-learning-book} Introduction, Markov Decision Processes and Temporal Difference learning chapters in order to understand the basis of Reinforcement learning.
\item Begin implementing the Radiance Volume data structure specified in \cite{dahm2017learning}.
\end{enumerate}

\subsection{Research/Implementation Goals}
I began my week by first reading the Reinforcement Learning textbook \cite{reinforcement-learning-book} as to attain the second goal. I took many notes and gained a good understanding of temporal difference learning and how it builds on Markov Decision Processes as a model for reinforcement learning. I then read the NVIDIA paper  \cite{dahm2017learning} which I found out that I needed to use Expected Sarsa as my form of temporal difference learning for the path tracing algorithm created by NVIDIA. 

From this reading I found that I needed to first convert my ray-tracer into a path-tracer, where we simulate light paths (rays) bouncing round the room until they hit a light surface. Only when the ray intersects with an area light does it gain luminance which then dictates the irradiance of a given point in the room along with the diffuse surfaces it bounced off. This required me to remodel my point light and convert it into an area light as well as redesign my implementation of \verb|Triangles| and create the child classes \verb|Surfaces| and \verb|AreaLight| which extend from it. Whilst also modifying the ray-tracing Monte Carlo global illumination method to be a path-tracing Monte Carlo global illumination method \cite{pathtracing}. Instead of scattering the rays every bounce, I instead sample many rays for a single pixel to begin with and just trace that single ray until it reaches a light source (or other terminating conditions).

With the path-tracer ready, I was able to begin working on reimplementing the data structure which \cite{dahm2017learning} relies on, The Irradiance Volume \cite{greger1998irradiance}. The irradiance volume data structure stores the irradiance for many sampled points in the room, for which when you intersect with some geometry in the scene, you can interpolate between the precomputed irradiance values stored at these points to find the predicted irradiance at any point in the scene. The more sample points you have in the room the more accurate your estimate will be. For every sampled point the irradiance is calculated by finding the radiance at the given point by calculating all light incoming from uniformly sampled discretized angles (a grid converted into a hemisphere around the sample point). I managed to implement a single Irradiance Hemisphere and visualise it in the scene before the end of the week.

\subsection{Resources}
The most useful sources this week were the NVIDIA paper \cite{dahm2017learning} (which I will no longer mention in these sections as the thesis is essentially based around it) and the reinforcement learning book \cite{reinforcement-learning-book}.

\subsection{Reflection}
This week was different from those so far, I really focused on research and have a lot of notes to show for it, as compared to the past two weeks which have essentially been based around implementation of a ray-tracer. The work is getting more challenging and open to thought and interpretation of what cutting edge work has already been done by NVIDIA. I can safely say I met my 3 goals I outlined for this week.

\section*{Week 4}
I now have a basis point to start off with the Irradiance Volume \cite{greger1998irradiance} implementation as I have successfully simulated a single \verb|RadianceVolume| (class). It was now time to build this structure into the rendering pipeline and using these sampled point estimates into my approximation of global illumination for given point in the scene.

\subsection{Goals}
\begin{enumerate}
\item Find a way to sample radiance volumes around the scene uniformly and use their estimates in the rendering pipeline to create a perceptually realistic image.
\item Create KD-Tree in order to quickly look up the closest Radiance Volumes around a given point in the scene. Also introduce the \verb|icc| Intel compiler to speed up programs performance.
\item Use Trilinear interpolation between the radiance volumes in the scene to find the irradiance estimate for a given point in the scene.
\item Begin implementing the reinforcement learning approach with the Irradiance Volume data structure.
\end{enumerate}

\subsection{Research/Implementation Goals}
As for the first goal, I decided to sample the radiance volumes uniformly by sampling $n$ radiance volumes on a given surface (using that surfaces normal), where the value of $n$ is determined by the area of that triangle. This meant the algorithm is able to adapt to different scenes. This is different to what is proposed by \cite{greger1998irradiance} where a bilevel grid is used. This would likely give a more accurate estimate on surfaces as will focus all of our radiance volumes on surfaces rather then in the middle of the scene. This technique seems to produce good quality images.

The KD-Tree was a fairly straightforward implementation based upon code from my 3rd year computer graphics unit we implemented for a Photon Map. This made it quick to get working for an irradiance volume data structure and

\subsection{Resources}

\subsection{Reflection}


\bibliographystyle{plain}
\bibliography{weekly-summaries}



\end{document}
