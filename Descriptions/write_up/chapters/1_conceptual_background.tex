\documentclass[../dissertation.tex]{subfiles}

\begin{document}

\chapter{Introduction}
\label{chap:context}

The aim of this chapter is to give a tour of the concepts we will be working with and set out a clear motivation for why we believe or work is necessary. We will avoid delving into any technical depth here, the pre-requisite knowledge to understand our work is instead given in chapter \ref{chap:technical_background}. Our journey begins with an overview of Monte Carlo path tracing and how importance sampling is beneficial for this. Next, we introduced temporal difference learning as a branch of Reinforcement Learning and how this relates to light transport for path tracing. Finally, we give our wider motivation for our work, as well as our objectives and the significant challenges standing in the way of achieving them.

\section{Monte Carlo Path Tracing for Light Transport Simulation}
\label{sec:conceptual_path_trace}
Monte Carlo path tracing, more generally known as path tracing, is a Monte Carlo method for rendering photo-realistic images of 3D  scenes by accurately approximating global illumination \cite{christensen2016path}. Figure \ref{fig:path_tracing_overview} summarises on a high level how path tracing produces a 2-dimensional image of a 3-dimensional scene. For each pixel multiple rays are shot from the camera through the pixel and into the scene. Any ray which intersects with an area light terminates, otherwise a new direction is sampled for the ray and it is continued in this sampled direction. This process is repeated until all rays have intersected with an area light.  At which point, the pixel colour value can  be found by computing a Monte Carlo approximation of an integral, the details of which are discussed in chapter \ref{chap:technical}. Each rays colour estimate is calculated based on the material surface properties it intersects with before intersecting with the light, as well as the area lights properties it intersected with. The full path of a ray takes from the camera to intersecting with an area light is known as a \textit{light path}, and we will use this terminology from here on. Therefore, each sampled light path represents a sample used to solve an integral to determine a pixels colour values by Monte Carlo integration. The more Sampled light paths Per Pixel (SPP), the more accurate the Monte Carlo approximation is of the integral to determine the pixels colour value. Meaning, the higher the SPP, the lower the noise in each pixel and in turn, the rendered image \cite{kajiya1986rendering}. 

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.8\textwidth]{images/path_tracing.png}    
\end{center}
\caption{An illustration of path tracing, where three light paths are traced from the camera through a pixel, to the light source in a simple 3D scene. The light paths are used to determine the pixel colours of the rendered image.}
\label{fig:path_tracing_overview}
\end{figure}

Path tracing is said to simulate \textit{light transport} \cite{keller2016path}, meaning it simulates the interactions of photons with surfaces. This is achieved by the process described above where each light path can be thought of as a photon. However, light paths in path tracing begin from the camera and reflect off surfaces until until they intersect with a light source, whereas in reality photons begin from the light source and reflect off surfaces until they intersect with the camera lens. It turns out that simulating light paths in this way is identical to simulating photons how they naturally occur, because the physics behind light transport does not change if the paths are reversed \cite{stanford_graphics}. This means path tracing is able faithfully simulate light transport whilst only simulating light paths that intersect with the camera lens to contribute to the image.

As path tracing simulates light transport, it also simulates global illumination as it accounts for both direct and indirect illumination. Direct illumination light paths which contribute to the image by reflecting off a exactly one surface before intersecting with a light source. Whereas  indirect illumination is where light paths reflect 2 or more times before reaching a light source. In figure \ref{fig:direct_and_global}, an identical scene is shown with only direct illumination (left) and the other with global illumination (right). The globally illuminated scene displays a range of light effects, which are not present in the directly illuminated scene  For example, effects such as; colour bleeding which is clear on the white walls by the boxes, soft shadows of the boxes silhouette, and indirect diffuse lighting causes the shadow of the box to not be pitch black. These light effects are achieved by a simple process of determining each pixels colour value individually. This allows artists to increase productivity and perform less manual image tweaking in the production of photo-realistic images. Due to this, the Computer Graphics industry has seen a large resurgence in research and usage of path tracing and other rendering methods which simulate light trasnport in the past decade \cite{krivanek2014recent}.

\begin{figure}[h!]
\centering
\begin{minipage}{.45\textwidth}
\includegraphics[width=0.99\textwidth]{images/renders/cornell/direct_light.png}    
\subcaption{Direct Illumination}
\end{minipage}\hspace{2em}
\begin{minipage}{.45\textwidth}
\includegraphics[width=0.99\textwidth]{images/renders/cornell/2048_300_default.png}    
\subcaption{Global Illumination}
\end{minipage}
\caption{Two renders of the Cornell Box, where the left is directly illuminated and the right is globally illuminated.}
\label{fig:direct_and_global}
\end{figure}

Importance sampling can be used in path tracing to improve the rendered image quality when using the same number of SPP. The reason being is that directions to continue a light path in for the default path tracing algorithm are sampled at uniformly at random. However, some directions will lead to light path contributing more to the approximated colour value of a pixel than others. These directions are said to be more 'important'. We wish to sample important directions more often as they will reduce the variance in our Monte Carlo approximation of a pixels colour value, which is otherwise known as a reduction in noise. Therefore, by using importance sampling we can construct light paths in such a way that they are more likely to reduce the noise in each pixels colour estimate, producing higher quality rendered images using the same number of SPP. An example of this reduction in noise can be see in \ref{fig:noise_reduction_simple_room}, where the default path tracers output is compared to our implementation of NVIDIA's path tracer \cite{dahm2017learning}, which uses Importance sampling. Note, any other rendering algorithm which simulates light transport can benefit from importance sampling, as they are all derived from the \textit{rendering equation} \cite{jensen1996global, keller2016path} which we will detail in chapter \ref{chap:technical_background}.

\begin{figure}[h]
\centering
\begin{minipage}{.45\textwidth}
\includegraphics[width=0.99\textwidth]{images/renders/simple_room/default_16.png}    
\subcaption{Default Forward Path Tracer}
\end{minipage}\hspace{2em}
\begin{minipage}{.45\textwidth}
\includegraphics[width=0.99\textwidth]{images/renders/simple_room/reinforcement_16.png}    
\subcaption{Expected Sarsa Path Tracer}
\end{minipage}
\caption{Two renders of a simple room using 16 SPP. Where one does not use importance sampling in the construction of light paths (left), and the other does so based on a reinforcement learning rule \cite{dahm2017learning} (right). A clear reduction in image noise can be seen by the use of importance sampling.}
\label{fig:noise_reduction_simple_room}
\end{figure}

\section{Temporal Difference Learning for Importance Sampling Ray Directions}
\label{sec:td_learn_for_importance}

We will be using temporal difference learning techniques to find out which directions are important to continue light paths in during path tracing. This section answers three important questions to detail our motivation behind doing this; a) what is temporal difference learning?  b) How can temporal difference learning methods be used to importance sample new ray directions for a given intersection point in the scene? c) Why use temporal difference learning methods over other Importance sampling methods to do so? 

\subsection{What is Temporal Difference learning?}
Temporal difference learning, which I will refer to from here on as TD-learning, is a set of model free Reinforcement learning methods. Firstly, Reinforcement learning is the process of an AI agent learning what is the best action to take in any given state of the system it exists within, in order to maximise a numerical reward signal \cite{sutton2011reinforcement}. The AI agent is not told which actions are  best to take in a given state, but instead it must learn which ones are by trialling them and observing the reward signal. Actions taken may not only affect the immediate reward, but all subsequent rewards received for taking future actions. For example, picture a robot rover whose duty it is to explore the surrounding area as much possible. A state in this case is any sensory data the robot has, such as camera for observing its surroundings. Its possible actions are the directions to move in for a set distance. If it discovers a new area, it receives a positive reward signal, otherwise the reward signal is zero. Now, if the robot chooses to explore a given area it may not be able to get back from, say a canyon, the robot is limited to searching areas reachable from the canyon. Hence, all subsequent reward signals are limited to what can be received from exploration of the canyon, compared to not entering the canyon and exploring areas which can be returned from first.

\subsection{Temporal Difference learning methods for Efficient Light Transport Simulation}

 As a small introduction to how reinforcement learning can be applied to light transport simulation, a state, action, and reward signal in the context of light transport simulation within path tracing are given below.

\begin{itemize}

\item \textbf{State}: A 3D intersection position of light path in the scene.

\item \textbf{Action}: Continuing a light path in a given direction from the current 
state.

\item \textbf{Reward Signal}: The amount of light received by the next intersection location
of the light path when continued in the direction sampled.
was sampled in.

\end{itemize}

In this setting, we can use TD-learning methods to create an AI agent which learns by taking different actions in different states, which then observes their reward signals to find out for each state which actions have the highest valuations. By then converting the action space into a probability distribution weighted by each actions learned valuation, the AI agent can sample from this distribution to increase the average light paths contribution to a pixel, reducing the noise in rendered images. 

\subsection{Why use Temporal Difference Learning for Importance Sampling?}

Traditional Importance sampling techniques for path tracing do not take into account the visibility of the object from light source \cite{dahm2017learning}. A light blocker is shown in \ref{fig:blocker}, where the  blocking object stops rays from directly reaching the light. Due to the unknown presence of blockers, traditional importance sampling methods can fail to avoid sampling zero contribution light paths. Therefore, scenes which are significantly affected by blockers will not receive the benefits from traditional Importance sampling and can even benefit more from an uniform sampling scheme \cite{ramamoorthi2012theory}.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.3\textwidth]{images/light_blocker.png}    
\end{center}
\caption{An illustration of a light blocker for an importance sampling scheme which does not consider visibility. Each arrow represents a possible direction the light path will be continued in. Clearly the reflected light path is likely to hit the blocker, reducing its contribution to the approximation of a pixel value.}
\label{fig:blocker}
\end{figure}

Temporal difference learning methods are better equipped to tackle this problem \cite{dahm2017learning}. As the AI agent described in the previous section learns which directions light is coming from in the scene and concentrates its sampling towards these directions. Directions leading to blockers will have a low value, hence it is unlikely the AI agent will sample rays in these directions. In fact, we have described that the agents goal is equivalent to learning what is known as the \textit{incident radiance function}. The incident radiance describes the power of light incident on a surface at a given point from a given direction.

\subsection{From Discrete to a Continuous State Space}

\section{Motivation}
\label{sec:motivation}

Rendering time of my graphics engine is not something I have tried to heavily 
optimise. I instead focus on producing higher quality images using the same 
number of samples per pixel in light transport simulation in hope that future 
work will find ways of optimising my methods for speed. Therefore, my work 
still aims to contribute to the wider goal seen in computer graphics to use 
accurate light transport simulation in the rendering of photo-realistic images 
for complex scenes in real-time.  Speeding up the methods I use is a large 
topic in itself, requiring a deep investigation into the best software, hardware, 
and parallel programming paradigms to use.\\

\subsection{Real time Rendering using Accurate Light Transport Simulation}
The motivation for using accurate light transport simulation in real-time 
comes from the clear superior visual quality of images rendered using this 
techniques, compared to that of scanline methods which are currently used. 
Where scanline rendering, also known as rasterizing, is the current computer 
graphics industry standard method for real-time rendering. Not only are 
renders for a wide range of scenes clearly superior from methods which 
accurately simulate light transport, but they also scale far better with the 
number of polygons used to build the scenes surfaces. Therefore, scanline 
rendering for scenes with extremely complex geometry in real-time is currently 
not and option. Accurate light transport simulation methods therefore have 
great potential to be used in ultra realistic simulations for applications such 
as scenario planning and virtual reality learning environments \cite{pan2006virtual}. 
Also, many games sell realism as one of their most important features, therefore 
developing photo-realistic graphics in real-time has clear economic incentive for 
the video games industry which was valued at over \$$136$ by the end of 2018 
\cite{bloomberg.com}. An economic incentive can also be seen for the film
industry, where reductions in render times lead to a direct saving on compute 
time, as well as the hardware required to render full length films.

\subsection{Recent Developments}
Due to the incentives, a large amount of research and investment has been focused 
on purpose built hardware and Deep learning  post-processing methods in an 
attempt to bring accurate light transport simulation into real-time. NVIDIA's 
Turing Ray Tracing Technology \cite{nvidia_turing_architecture_whitepaper_2018} 
represents a significant leap in the hardware to support light transport simulation. 
It allows for real-time graphics engines to be a hybrid of both scanline rendering, 
and ray-tracing. The 20 series Turing GPU architecture has significantly improved 
the speed of ray-casting for light transport simulation, and has the capacity for  
simulating 10 Giga Rays per second. However, using this hardware alone with 
current rendering methods is not enough to perform accurate light transport 
simulation for complex scenes in real-time.\\

Post-processing methods are designed to take a noisy input image produced by a 
render which simulates light transport, and then reconstruct the image to remove 
the noise present in the image. Generally these methods rely on pre-trained deep 
neural networks to reconstruct the image far quicker then it would take for the 
renderer to produce an image of the same visual quality \cite{bako2017kernel}. 
Once again NVIDIA has made significant advancements in this area with NVIDIA 
OptiX AI Accelerated Denoiser, which is based on their newly designed recurrent 
denoising autoencoder \cite{chaitanya2017interactive}. OptiX has been successfully 
integrated in to many of the top rendering engines which accurately simulate light
transport, such as RenderMan \cite{christensen2018renderman} and Arnold 
\cite{georgiev2018arnold}. Whilst post-processing has significantly reduced the 
number of samples required to render photo-realistic images, there is still more 
work to be done to produce these images in real-time.\\

By using importance sampling by TD learning to reduce the number of samples 
required for accurate light transport simulation, the same standard of noisy 
image can be fed into an AI accelerated denoiser with fewer samples per pixel 
in light transport simulation. Running a rendering engine optimised in this way on 
purpose built hardware could make accurate light transport simulation for 
rendering photo-realistic images closer than it ever has been to real-time.

\section{Challenges and Objectives}

% Needs work

As previously mentioned, there already exists an example of TD learning used 
for importance sampling ray directions in a forward Path tracer \cite{dahm2017learning}. 
However, further methods of analysis need to be conducted upon this new 
method to determine its performance for reducing the number of zero contribution l
ight paths for different scenes with different settings. It is difficult to assess this as 
there are infinitely many scenes the method can be used to render, so coming to a 
clear conclusion is difficult. Another difficult task is that of designing an algorithm 
for an AI agent to learn what are the favourable directions to sample in a scene are 
using the deep Q-learning method. This includes some important unanswered 
questions, such as; is it possible for a deep neural network to model all Q values for 
a continuous scene space? If so, what is a suitable network architecture? All of 
which I will describe in more depth in Chapter \ref{chap:deep-q}. Then the actual 
task of implementing such an algorithm in a graphics engine written from scratch 
is non-trivial due to the technologies which will need to be combined together. 
The algorithm must also run fast enough to collect large amounts of data from, 
otherwise a justified conclusion on its performance cannot be made. Therefore, 
the algorithm will have to be parallelized and run on a GPU.\\

As previously mentioned, my main goal is to investigate the ability of two 
different temporal difference learning algorithms ability to reduce the number 
of zero contribution light paths in path tracing, whilst still accurately 
approximating global illumination. Which can be broken down in to the 
following objectives:

\begin{enumerate}
\item Reimplement Nvidia's state of the art on-line Temporal 
Difference learning Path Tracer in order to further investigate its ability
to reduce the number of zero contribution light paths.

\item Design and implement an on-line Deep Q-Learning variant of the
Path tracing algorithm and investigate its ability to reduce the number of zero contribution light paths sampled.

\item Assess both Nvidia's state of the art on-line Temporal Difference 
learning Path tracer, and the Deep Q-Learning Path tracer' on their ability 
to accurately simulate Global Illumination.

\end{enumerate}


\begin{comment}
{\bf A compulsory chapter,     of roughly $5$ pages}
\vspace{1cm} 

\noindent
This chapter should describe the project context, and motivate each of
the proposed aims and objectives.  Ideally, it is written at a fairly 
high-level, and easily understood by a reader who is technically 
competent but not an expert in the topic itself.

In short, the goal is to answer three questions for the reader.  First, 
what is the project topic, or problem being investigated?  Second, why 
is the topic important, or rather why should the reader care about it?  
For example, why there is a need for this project (e.g., lack of similar 
software or deficiency in existing software), who will benefit from the 
project and in what way (e.g., end-users, or software developers) what 
work does the project build on and why is the selected approach either
important and/or interesting (e.g., fills a gap in literature, applies
results from another field to a new problem).  Finally, what are the 
central challenges involved and why are they significant? 
 
The chapter should conclude with a concise bullet point list that 
summarises the aims and objectives.  For example:

\begin{quote}
\noindent
The high-level objective of this project is to reduce the performance 
gap between hardware and software implementations of modular arithmetic.  
More specifically, the concrete aims are:

\begin{enumerate}
\item Research and survey literature on public-key cryptography and
      identify the state of the art in exponentiation algorithms.
\item Improve the state of the art algorithm so that it can be used
      in an effective and flexible way on constrained devices.
\item Implement a framework for describing exponentiation algorithms
      and populate it with suitable examples from the literature on 
      an ARM7 platform.
\item Use the framework to perform a study of algorithm performance
      in terms of time and space, and show the proposed improvements
      are worthwhile.
\end{enumerate}
\end{quote}


\textbf{Preliminary}
\begin{enumerate}
\item Path-tracing in industry/ray-tracing in general, why is it important 
and how is the current field moving. Why should we optimise it algorithmically. 
Why should the reader care about path-tracing? - Usage in films, increasing
 interest for real-time simulations and gaming industry which is worth lots of money

\item High level overview of path-tracing: specifically must explain why it takes 
so long and why we care about the number of samples

\item In the path-tracing algorithm, a single pixel's colour is determined by firing 
multiple rays from the camera, through that pixel into the scene and building a 
colour value estimate for each one, then averaging their values to get the pixels 
colour. Each rays colour estimate is computed by estimating a solution to the recursive
Rendering Equation (cite). The path-tracing algorithms estimate to this solution involves 
scattering the ray around the scene until it intersects with a light source. Therefore, if a
 ray is scattered in a direction with zero-light contribution, but other sampled rays are not,
  a noisy estimate is achieved for the pixel value unless many rays are sampled to 
  reduce the effect of this noise. Therefore, avoiding  scattering rays in directions of 
  zero-light power contribution can reduce the number of samples needed to achieve 
  an accurate estimate of a pixels colour value.

\item Work was primarily motivated by Ken \& Dahms paper for modelling the irradiance
 distribution in order to reduce the number of zero-contribution light transport paths 
 traced. Nvidia are world leaders in GPU manufacturing and drive the computer 
 graphics forward.

\item Literature around efficiently simulating light transport - it's applicability to all 
modern used off-line rendering techniques

\item Aims \& Challenges:

\begin{enumerate}
\item Implementing a path-tracer for diffuse surfaces from scratch using only maths 
and pixel libraries as helper functions which can handle imports of a custom scene
\item Accelerating path-tracer on Cuda to get results in a reasonable time
\item Implementing the irradiance volume data-structure and sampling technique which 
can adapt to any size scene
\item Implementing Ken Dahms proposed path-tracing algorithm with nearest neighbour
 search of KD-Tree on a GPU efficiently 
\item Researching reinforcement learning: TD-Learning \& deep reinforcement learning - 
never been taught before, so self taught with resources on-line
\item Training a network on pre-computed Q values to check if it is possible for a neural
 network to learn the irradiance distribution function for a set of points in a scene
\item Designing an algorithm to integrate deep reinforcement learning into the 
rendering pipeline for a path-tracer
\item Choosing a set of metrics to evaluate the algorithms performances on
\item Accelerating the algorithms via Cuda to run on Nvidia GPU
\end{enumerate}

\end{enumerate}
\end{comment}

\end{document}